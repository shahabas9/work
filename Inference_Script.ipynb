{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json,pickle,math\n",
    "import logging, argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml , argparse\n",
    "import multiprocessing.dummy as mp\n",
    "from deploy_utils import make_sure_path_exists\n",
    "from deploy_utils import visualize_output_dict\n",
    "from deploy_utils import Infer_From_Model\n",
    "from deploy_utils import load_json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(detection_boxes, detection_classes, detection_scores,detection_features,detection_threshold):\n",
    "    \"\"\"\n",
    "    Function Definition : This function does default post processing for Extract Features script [ Infer model ] does Class wise Threshold\n",
    "    \"\"\"\n",
    "    filtered_boxes, filtered_classes, filtered_scores,filtered_features = [], [], [],[]\n",
    "    for b, c, s ,f in zip(detection_boxes, detection_classes, detection_scores,detection_features):\n",
    "        if s>=(detection_threshold[c]):\n",
    "            filtered_boxes += [b]\n",
    "            filtered_classes += [c]\n",
    "            filtered_scores += [s]\n",
    "            filtered_features += [f]\n",
    "    filtered_boxes = np.asarray(filtered_boxes)\n",
    "    filtered_classes = np.asarray(filtered_classes)\n",
    "    filtered_scores = np.asarray(filtered_scores)\n",
    "    filtered_feature_array = np.asarray(filtered_features)\n",
    "    return filtered_boxes, filtered_classes, filtered_scores,filtered_feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images_dir = \"/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/\"\n",
    "filename_type = [\"23975695_V_0_OD.png\"]\n",
    "output_json_dir = \"/jidoka/workspace/jdisk2/Shahabas/sidemismatch/sim_1/json\"\n",
    "os.makedirs(output_json_dir,exist_ok=True)\n",
    "output_result_dir = \"/jidoka/workspace/jdisk2/Shahabas/sidemismatch/sim_1/result\"\n",
    "os.makedirs(output_result_dir,exist_ok=True)\n",
    "model_path = \"/jidoka/simulations/jdisk2/jt.cust.Sansera_CR/sim_object_detection/Station_5_Side_Camera/sim_5/analysis/infer_model_4000/\"\n",
    "classnames =    [\"None\",\"Component_ID\",\"Crack\",\"Damage\",\"Steel_Shot\",\"Underfill\",\"Scales\",\"Flash\",\"Embossing\",\"Part_Without_Piercing\",\"Bend\",\"Rust\",\"Scale_Pit_Mark\",\n",
    "                \"Length_Mismatch\",\"Side_Mismatch\",\"corner_detection\",\"Defect_16\",\"Defect_17\",\"Defect_18\",\"Defect_19\",\"Defect_20\"]\n",
    "detection_threshold = [\"None\",0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.1,0.3,0.3,0.3,0.3,0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "defectwise_split = \"/jidoka/workspace/jdisk2/Shahabas/sidemismatch/sim_1/defectwise/\"\n",
    "for class_id in classnames[1:]:\n",
    "    defectwise_path = os.path.join(defectwise_split,class_id)\n",
    "    os.makedirs(defectwise_path,exist_ok=True)\n",
    "    \n",
    "ok_dir = defectwise_split+\"/ok\"\n",
    "ng_dir = defectwise_split+\"/ng\"\n",
    "os.makedirs(ok_dir,exist_ok=True)\n",
    "os.makedirs(ng_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_filename(input_images_dir):\n",
    "    \"\"\"\n",
    "    FUnction Definition : this function extracts the filename which we require\n",
    "    \"\"\"\n",
    "    print('----------------------------------------------------------------------------------------------------------')\n",
    "    print(\"Total Number of Images in Directory :- \",len(os.listdir(input_images_dir)))\n",
    "    print('----------------------------------------------------------------------------------------------------------')\n",
    "    filenames = os.listdir(input_images_dir)\n",
    "    total_count = []\n",
    "    seperated_filenames = []\n",
    "    i = 0\n",
    "    for filename_id in range(len(filename_type)):\n",
    "        for filename_cnt in filenames:\n",
    "            if filename_type[filename_id] in filename_cnt:\n",
    "                i += 1\n",
    "                seperated_filenames += [filename_cnt]\n",
    "            total_count = i \n",
    "        print(\"Total Number of Images Selected     :- \",total_count)\n",
    "        print('----------------------------------------------------------------------------------------------------------')\n",
    "    return seperated_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------\n",
      "Total Number of Images in Directory :-  130\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Total Number of Images Selected     :-  9\n",
      "----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "seperated_filenames = seperate_filename(input_images_dir)\n",
    "img_list = []\n",
    "for file in seperated_filenames:\n",
    "    list_path = os.path.join(input_images_dir,file)\n",
    "    img_list.append(list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151803_SMCR1002FO01_L_1_C_8_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151716_SMCR1002FO01_L_1_C_1_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151747_SMCR1002FO01_L_1_C_6_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151759_SMCR1002FO01_L_1_C_7_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151739_SMCR1002FO01_L_1_C_5_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151724_SMCR1002FO01_L_1_C_2_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151730_SMCR1002FO01_L_1_C_3_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151834_SMCR1002FO01_L_1_C_9_S_5_Cam_23975695_V_0_OD.png',\n",
       " '/jidoka/workspace/jdisk2/Shahabas/241-03-2023 Length mis match/230324-151735_SMCR1002FO01_L_1_C_4_S_5_Cam_23975695_V_0_OD.png']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy encoder for inference\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self,obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "            np.int16, np.int32, np.int64, np.uint8,\n",
    "            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,(np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Json function to save json files from model\n",
    "def save_json(output_dict,png_filename,output_pickle_dir):\n",
    "    output_str = json.dumps(output_dict, cls=NumpyEncoder)\n",
    "    if '.' in png_filename:\n",
    "        filename_without_ext = os.path.splitext(png_filename)[0]\n",
    "    else:\n",
    "        filename_without_ext = png_filename\n",
    "    json_save_path = os.path.join(output_pickle_dir, filename_without_ext+'.json')\n",
    "\n",
    "    with open(json_save_path, 'w') as f:\n",
    "        f.write(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----INFERENCE COMPLETED FOR : 230324-151803_SMCR1002FO01_L_1_C_8_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151716_SMCR1002FO01_L_1_C_1_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151759_SMCR1002FO01_L_1_C_7_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151724_SMCR1002FO01_L_1_C_2_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151834_SMCR1002FO01_L_1_C_9_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151747_SMCR1002FO01_L_1_C_6_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151739_SMCR1002FO01_L_1_C_5_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151730_SMCR1002FO01_L_1_C_3_S_5_Cam_23975695_V_0_OD.png -----\n",
      "-----INFERENCE COMPLETED FOR : 230324-151735_SMCR1002FO01_L_1_C_4_S_5_Cam_23975695_V_0_OD.png -----\n"
     ]
    }
   ],
   "source": [
    "selected_camera = [\".png\"]\n",
    "def infer_tfinfer_and_save(model, selected_camera,img_path):\n",
    "    json_save_dict = {}\n",
    "    newoutput_dict = {}\n",
    "    input_img_dir, img_name = os.path.split(img_path)\n",
    "    if \".png\" in img_name:\n",
    "        img = cv2.imread(img_path)\n",
    "        print(\"-----INFERENCE COMPLETED FOR :\",img_name,\"-----\")\n",
    "        for i in range(len(selected_camera)):\n",
    "            if selected_camera[i] in img_name:\n",
    "\n",
    "                output_dict = model.run_inference_for_single_image_features(img)\n",
    "                \n",
    "                detection_boxes = output_dict['detection_boxes']\n",
    "                detection_classes = output_dict['detection_classes']           \n",
    "                detection_scores = output_dict['detection_scores']\n",
    "                detection_features = output_dict['detection_features'] \n",
    "                \n",
    "                json_save_dict[\"detection_boxes\"]=detection_boxes  \n",
    "                json_save_dict[\"detection_classes\"]=detection_classes \n",
    "                json_save_dict[\"detection_scores\"]=detection_scores\n",
    "                               \n",
    "                 \n",
    "                save_json(json_save_dict,img_name,output_json_dir)\n",
    "                \n",
    "                detection_boxes, detection_classes, detection_scores ,detection_features= postprocess(detection_boxes, detection_classes, detection_scores,detection_features,detection_threshold)    \n",
    "\n",
    "                newoutput_dict[\"detection_scores\"]=detection_scores\n",
    "                newoutput_dict[\"detection_classes\"]=detection_classes                \n",
    "                newoutput_dict[\"detection_boxes\"]=detection_boxes     \n",
    "                newoutput_dict[\"detection_features\"]=detection_features\n",
    "                newoutput_dict[\"num_detections\"]=len(detection_classes)\n",
    "\n",
    "                category_index = {}\n",
    "                for i, classname in enumerate(classnames):\n",
    "                    category_index[i] = {'name': classname}  \n",
    "                    \n",
    "                save_json(newoutput_dict,img_name,output_result_dir)            \n",
    "\n",
    "\n",
    "multiprocess = 2 \n",
    "tf_infer_pool = []\n",
    "\n",
    "model = Infer_From_Model(model_path, log_level=logging.DEBUG)\n",
    "\n",
    "tf_infer_pool = []\n",
    "for k in range(multiprocess):\n",
    "    tf_infer_pool.append(mp.Pool(1))\n",
    "    \n",
    "images_for_tf_infer_pool = {}\n",
    "for k in range(multiprocess):\n",
    "    images_for_tf_infer_pool[k] = []\n",
    "\n",
    "target_container = 0\n",
    "for img_path in img_list:\n",
    "    input_img_dir, img_name = os.path.split(img_path)\n",
    "    images_for_tf_infer_pool[target_container].append(img_path)\n",
    "    target_container += 1 \n",
    "    if target_container == 2:\n",
    "        target_container = 0\n",
    "\n",
    "result_objs = []\n",
    "for k in range(multiprocess):\n",
    "    for j in range(len(images_for_tf_infer_pool[k])):\n",
    "        result_objs.append(tf_infer_pool[k].apply_async(infer_tfinfer_and_save,(model,selected_camera,images_for_tf_infer_pool[k][j])))  \n",
    "r = [result.get() for result in result_objs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secound Time Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames =    [\"None\",\"Component_ID\",\"Crack\",\"Damage\",\"Steel_Shot\",\"Underfill\",\"Scales\",\"Flash\",\"Embossing\",\"Part_Without_Piercing\",\"Bend\",\"Rust\",\"Scale_Pit_Mark\",\n",
    "                \"Length_Mismatch\",\"Side_Mismatch\",\"corner_detection\",\"Defect_16\",\"Defect_17\",\"Defect_18\",\"Defect_19\",\"Defect_20\"]\n",
    "detection_threshold = [\"None\",0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.1,0.3,0.3,0.3,0.3,0.3]\n",
    "\n",
    "output_result_dir = \"/jidoka/workspace/jdisk2/Shahabas/sidemismatch/sim_1/rerun/\"\n",
    "os.makedirs(output_result_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "defectwise_split = \"/jidoka/workspace/jdisk2/Shahabas/sidemismatch/sim_1/defectwise/\"\n",
    "for class_id in classnames[1:]:\n",
    "    defectwise_path = os.path.join(defectwise_split,class_id)\n",
    "    os.makedirs(defectwise_path,exist_ok=True)\n",
    "    \n",
    "ok_dir = defectwise_split+\"/ok\"\n",
    "ng_dir = defectwise_split+\"/ng\"\n",
    "os.makedirs(ok_dir,exist_ok=True)\n",
    "os.makedirs(ng_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(detection_boxes, detection_classes, detection_scores,detection_threshold):\n",
    "    \"\"\"\n",
    "    Function Definition : This function does default post processing for Extract Features script [ Infer model ] does Class wise Threshold\n",
    "    \"\"\"\n",
    "    filtered_boxes, filtered_classes, filtered_scores = [], [], []\n",
    "    for b, c, s  in zip(detection_boxes, detection_classes, detection_scores):\n",
    "        if s>=(detection_threshold[c]):\n",
    "            filtered_boxes += [b]\n",
    "            filtered_classes += [c]\n",
    "            filtered_scores += [s]\n",
    "    filtered_boxes = np.asarray(filtered_boxes)\n",
    "    filtered_classes = np.asarray(filtered_classes)\n",
    "    filtered_scores = np.asarray(filtered_scores)\n",
    "    return filtered_boxes, filtered_classes, filtered_scores\n",
    "\n",
    "def get_concat_images(img1, img2, individual_shape=(1024,1024)):\n",
    "    img1 = cv2.resize(img1, individual_shape)\n",
    "    img2 = cv2.resize(img2, individual_shape)\n",
    "    return np.concatenate([img1, img2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering   230324-151747_SMCR1002FO01_L_1_C_6_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151739_SMCR1002FO01_L_1_C_5_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151724_SMCR1002FO01_L_1_C_2_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151735_SMCR1002FO01_L_1_C_4_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151834_SMCR1002FO01_L_1_C_9_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151759_SMCR1002FO01_L_1_C_7_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151716_SMCR1002FO01_L_1_C_1_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151803_SMCR1002FO01_L_1_C_8_S_5_Cam_23975695_V_0_OD.png\n",
      "Infering   230324-151730_SMCR1002FO01_L_1_C_3_S_5_Cam_23975695_V_0_OD.png\n"
     ]
    }
   ],
   "source": [
    "inference_images_dir = \"/jidoka/workspace/jdisk2/Shahabas/sidemismatch/sim_1/inference\"\n",
    "os.makedirs(inference_images_dir,exist_ok= True)\n",
    "json_filenames = os.listdir(output_json_dir)\n",
    "\n",
    "for json_filename in json_filenames:\n",
    "    newoutput_dict = {}\n",
    "    image_id = json_filename[:-5]\n",
    "\n",
    "    curr_img_name = image_id + \".png\"\n",
    "    print(\"Infering  \",curr_img_name)\n",
    "\n",
    "    curr_img_path = os.path.join(input_images_dir, curr_img_name)\n",
    "\n",
    "    \n",
    "    curr_bbspecs = load_json(output_json_dir, json_filename)\n",
    "    \n",
    "    detection_classes = curr_bbspecs['detection_classes']           \n",
    "    detection_boxes = curr_bbspecs['detection_boxes']\n",
    "    detection_scores = curr_bbspecs['detection_scores']\n",
    "\n",
    "    \n",
    "    detection_boxes, detection_classes, detection_scores = postprocess(detection_boxes, detection_classes, detection_scores,detection_threshold)    \n",
    "\n",
    "    newoutput_dict[\"detection_scores\"]=detection_scores\n",
    "    newoutput_dict[\"detection_classes\"]=detection_classes                \n",
    "    newoutput_dict[\"detection_boxes\"]=detection_boxes     \n",
    "    newoutput_dict[\"num_detections\"]=len(detection_classes)\n",
    "\n",
    "    category_index = {}\n",
    "    for i, classname in enumerate(classnames):\n",
    "        category_index[i] = {'name': classname}  \n",
    "\n",
    "    save_json(newoutput_dict,curr_img_name,output_result_dir)\n",
    "\n",
    "    curr_img = cv2.imread(curr_img_path)\n",
    "    curr_img_vis = visualize_output_dict(curr_img, newoutput_dict,classnames=classnames[1:], min_score_thresh=0.0)   \n",
    "    save_img_path = os.path.join(inference_images_dir, curr_img_name)\n",
    "    images_side_by_side = get_concat_images(curr_img, curr_img_vis)\n",
    "    cv2.imwrite(save_img_path, images_side_by_side)\n",
    "    \n",
    "    if len(newoutput_dict[\"detection_classes\"]) == 0:\n",
    "        defectwise_save_path = os.path.join(defectwise_split, \"ok\",curr_img_name)\n",
    "        cv2.imwrite(defectwise_save_path, curr_img_vis)\n",
    "        \n",
    "    if len(newoutput_dict[\"detection_classes\"]) != 0:\n",
    "        defectwise_save_path = os.path.join(defectwise_split, \"ng\",curr_img_name)\n",
    "        cv2.imwrite(defectwise_save_path, curr_img_vis)\n",
    "        \n",
    "    for class_id in newoutput_dict[\"detection_classes\"]:\n",
    "        defectwise_save_path = os.path.join(defectwise_split, classnames[class_id],curr_img_name)\n",
    "        cv2.imwrite(defectwise_save_path, curr_img_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf15-gpu",
   "language": "python",
   "name": "tf15-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
